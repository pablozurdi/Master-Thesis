{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2334ee-6ba1-41b7-9536-298319928b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "from scipy.ndimage import rotate, zoom\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import wcsaxes\n",
    "from astropy.wcs import WCS\n",
    "import astropy.visualization as ax\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from photutils.detection import DAOStarFinder\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "from microfilm import colorify, microplot\n",
    "from skimage import exposure\n",
    "import scipy.optimize as opt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from photutils.datasets import make_4gaussians_image\n",
    "from photutils.centroids import (centroid_1dg, centroid_2dg,\n",
    "                                 centroid_com, centroid_quadratic)\n",
    "from mpl_toolkits.axes_grid1.inset_locator import (mark_inset, zoomed_inset_axes)\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2352e1-94d9-4569-a19e-efe5d3d70d9e",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1579c95-364f-4ff5-9b4b-92e58f049435",
   "metadata": {},
   "source": [
    "First, we make a list where all the images are saved.\n",
    "In my case I have the 4 images from HST specified in Sect. 2 of the master thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3910d3-4ad3-4d79-819d-fc75a7126bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\pablo\\\\Desktop\\\\TFM\\\\data\\\\HST\\\\'    # Where we have the images in our device\n",
    "fileList = sorted(glob.glob(path+'*.fits'))             # Sorting the list by name\n",
    "\n",
    "images = []                                             # Loop for saving the data corresponding to each image in this list\n",
    "for i in range(len(fileList)):\n",
    "    # From each FITS we work on the 2nd element, which is the SCI\n",
    "    hdu = fits.open(fileList[i])\n",
    "    data = hdu[1].data\n",
    "    images.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d5a1a-5d3b-4e46-816a-ecc90c146970",
   "metadata": {},
   "outputs": [],
   "source": [
    "wHST = WCS(hdu[1].header) # This is the projection we'll use when ploting these images\n",
    "                          # Make sure the transformation between pixel and celestial coordinates is the same for all images\n",
    "                          # If not, you must have a wcs for each image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e9485b-e4ec-4af4-82ed-d14b857261e7",
   "metadata": {},
   "source": [
    "# Continuum subtracted images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0f463e-42a1-4c6a-9631-4b98a6d273c6",
   "metadata": {},
   "source": [
    "Before subtracting the continuum image to the corresponding image captured with a narrow-filter, we have to calculate \n",
    "the factor that relates the fluxes of the wide and narrow-filter images. For that purpose, we obtain the flux of several \n",
    "standard stars in both images and do a linear regresion that gives us that factor. The tool used is DaoStarFinder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0109f29-cb65-41e0-9f8e-d078756c8797",
   "metadata": {},
   "source": [
    "## [FeII]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc95d94-afe6-4411-ba80-92bbd5a7d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "daofind_164 = DAOStarFinder(fwhm=3.0, threshold=4 * np.nanstd(images[3]))         # the threshold 4*std_164 results into 22 sources found\n",
    "mask_164 = np.zeros(images[3].shape, dtype=bool) \n",
    "mask_164[700:775, 750:810] = True                                                 # This masks the jet that we see at first sight\n",
    "sources_164 = daofind_164(images[3] - np.nanmedian(images[3]), mask=mask_164)     # 164 and 160 prefixes make allusion to the wavelgnth, \n",
    "                                                                                  # 1.64 and 1.60 microns respectively\n",
    "\n",
    "positions_164 = np.transpose((sources_164['xcentroid'], sources_164['ycentroid']))\n",
    "apertures_164 = CircularAperture(positions_164, r = 5.0)\n",
    "\n",
    "region_164, region_160 = images[3], images[2]\n",
    "phot_table_164 = aperture_photometry(region_164, apertures_164) \n",
    "phot_table_160 = aperture_photometry(region_160, apertures_164) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eca5d7-97c6-4814-973b-e0ea4d9082c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the nan values\n",
    "nan_indexes = []                                     # List where we save the positions of nan aperture_sum\n",
    "for i in range(len(phot_table_164)):\n",
    "    if np.isnan(phot_table_164[i]['aperture_sum']):\n",
    "        nan_indexes.append(phot_table_164[i]['id'])\n",
    "    elif np.isnan(phot_table_160[i]['aperture_sum']):\n",
    "        nan_indexes.append(phot_table_160[i]['id'])\n",
    "\n",
    "# Now we know the position of the nan values, we can proceed deleting that fluxes\n",
    "\n",
    "counter = 0\n",
    "while counter < len(phot_table_164):\n",
    "    if phot_table_160[counter]['id'] in nan_indexes:\n",
    "        del phot_table_164[counter]  \n",
    "        del phot_table_160[counter]\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1a0312-2dac-4aa4-94e5-d2034bbae5c8",
   "metadata": {},
   "source": [
    "I decided to label some parameters with \"large\" and \"short\" as I'll obtain two pure emission images, one for Paschen beta \n",
    "and another for [FeII] at 1.64 microns. \"Large\" is for [FeII] and \"short\" for Pa$\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcde19a-d29f-4e30-9de5-be753c6acdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_large = phot_table_160['aperture_sum']\n",
    "y_large = phot_table_164['aperture_sum']\n",
    "\n",
    "# There are 3-4 stars that doesn't follow the tend and all of them correspond to the highest fluxes,\n",
    "# so we discard them because the tendency might be different once a certain high value of the flow is reached\n",
    "\n",
    "x_large_list, y_large_list = [], []\n",
    "large_discarded_164, large_discarded_160 = [], []\n",
    "for element in range(len(phot_table_164)):\n",
    "    if x_large[element] < 70000:                   \n",
    "        x_large_list.append(x_large[element])\n",
    "        y_large_list.append(y_large[element])\n",
    "    else: \n",
    "        large_discarded_164.append(phot_table_164[element])\n",
    "        large_discarded_160.append(phot_table_160[element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17fc56-5303-4f94-95d2-2d8cbe80225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_large = np.polyfit(x_large_list, y_large_list, 1) \n",
    "region_160_resc = coefficients_large[0] * region_160\n",
    "pure_large = region_164 - region_160_resc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6dadc6-109b-46fc-9dd7-e3e8f5d320cf",
   "metadata": {},
   "source": [
    "This coefficient is the relation between the HST image at 1.60 microns with the one at 1.64;\n",
    "and pure_large is the continuum subtracted image (so-called pure emission image) at the \n",
    "larger wavelength in this work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbaf4bb-b96f-49cd-a71f-ad9aaaeeff24",
   "metadata": {},
   "source": [
    "## Pa$\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6786b085-568c-42ae-87e3-abc76eb93910",
   "metadata": {},
   "outputs": [],
   "source": [
    "daofind_110 = DAOStarFinder(fwhm=3.0, threshold=20 * np.nanstd(images[0]))\n",
    "mask_110 = np.zeros(images[0].shape, dtype=bool)\n",
    "mask_110[700:775, 750:810] = True\n",
    "sources_110 = daofind_110(images[0] - np.nanmedian(images[0]), mask=mask_110)\n",
    "\n",
    "region_128 = images[1]\n",
    "region_110 = images[0]\n",
    "positions_110 = np.transpose((sources_110['xcentroid'], sources_110['ycentroid']))\n",
    "apertures_110 = CircularAperture(positions_110, r = 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c52e846-9d69-4c55-82f3-faac9dcf7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_128 = np.transpose((sources_110['xcentroid'], sources_110['ycentroid']))\n",
    "apertures_128 = CircularAperture(positions_128, r = 5.0)\n",
    "phot_table_128 = aperture_photometry(region_128, apertures_128) \n",
    "phot_table_110 = aperture_photometry(region_110, apertures_128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d391e3-624b-4e56-9cd1-33eaa1419c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are stars that are very near to other star so their fluxes may be influenced by these other stars\n",
    "del phot_table_128[0] \n",
    "del phot_table_110[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c7389-442c-4068-9139-074de71bc001",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_short = phot_table_110['aperture_sum']\n",
    "y_short = phot_table_128['aperture_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fced76-a7f4-4892-b21f-116d4fd7be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same scenario as before, there are 3-4 stars that doesn't follow the tend\n",
    "x_short_list, y_short_list = [], []\n",
    "short_discarded_110, short_discarded_128 = [], []\n",
    "for element in range(len(x_short)):\n",
    "    if x_short[element] < 100000:\n",
    "        x_short_list.append(x_short[element])\n",
    "        y_short_list.append(y_short[element])\n",
    "    else:\n",
    "        short_discarded_128.append(phot_table_128[element])\n",
    "        short_discarded_110.append(phot_table_110[element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29489947-473e-40eb-b5d5-4f65442a3d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_short = np.polyfit(x_short_list, y_short_list, 1)\n",
    "\n",
    "region_110_resc = coefficients_short[0] * region_110\n",
    "pure_short = region_128 - region_110_resc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a965c249-48f2-4799-8365-186a348390f9",
   "metadata": {},
   "source": [
    "This coefficient is the relation between the HST image at 1.10 microns with the one at 1.28;\n",
    "and pure_short is the continuum subtracted image (so-called pure emission image) at the \n",
    "shorter wavelength in this work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438e20b5-356a-42b9-a9c6-b68f66bc614c",
   "metadata": {},
   "source": [
    "## Check of the images obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9cbd3-849e-4f42-a6aa-b9b3cabe28ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "ax = plt.subplot(projection=wHST)\n",
    "plt.imshow(pure_short, cmap='gist_gray', origin='lower', vmin=0, vmax=0.2, interpolation='nearest')\n",
    "plt.title('Continuum subtracted emission of [FeII]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e469c-470e-4e1d-937d-d6bc72bca870",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "ax = plt.subplot(projection=wHST)\n",
    "plt.imshow(pure_large, cmap='gist_gray', origin='lower', vmin=0, vmax=0.2, interpolation='nearest')\n",
    "plt.title(r'Continuum subtracted emission of Pa$\\beta$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63db1dd1-73b6-4b62-871d-cb522d417099",
   "metadata": {},
   "source": [
    "# Contour levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946452b1-a98f-452d-9f52-b0cb0e4c97bb",
   "metadata": {},
   "source": [
    "See Sect. 3.6 of the thesis for further details. This code only contains the part corresponding to one of the two\n",
    "regions where the contour levels have been computed, as the other is completely analogous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b0f39-488f-4e4e-8185-c363e28807bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to visualise regions with only background emission\n",
    "\n",
    "rect1 = patches.Rectangle((165, 170), 15, 15, linewidth=2, edgecolor='orange', facecolor='none')\n",
    "rect2 = patches.Rectangle((200, 180), 15, 15, linewidth=2, edgecolor='orange', facecolor='none')\n",
    "rect3 = patches.Rectangle((220, 305), 14, 14, linewidth=2, edgecolor='orange', facecolor='none')\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "ax = plt.subplot(projection=wHST[500:850, 600:950])   # This is what makes the axis to be recongnized as celestial coordinates\n",
    "plt.imshow(pure_large[500:850, 600:950], cmap = 'gist_gray', vmin = 0, vmax = 0.2, origin = 'lower')\n",
    "\n",
    "ax.add_patch(rect1)\n",
    "ax.add_patch(rect2)\n",
    "ax.add_patch(rect3)\n",
    "\n",
    "plt.ylabel('Dec (J2000)', fontsize=12)\n",
    "plt.xlabel('RA (J2000)', fontsize=12)\n",
    "plt.title('[FeII] - Squares with only background - Zone 1 ', fontsize=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2346bd5c-9528-4477-8bf0-bf224b21e9dd",
   "metadata": {},
   "source": [
    "The std can be modified a bit depending on the regions we select, that's why we should take an average of some regions.\n",
    "In our case we can find std between 0.016 and 0.024, hence the average value is around 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d13c10d-9859-4eda-8584-c53e9a955d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_large_zoomed = pure_large[500:850, 600:950]\n",
    "first_square_std = np.std(pure_large_zoomed[180:195, 201:216])\n",
    "second_square_std = np.std(pure_large_zoomed[305:329, 220:234])\n",
    "third_square_std = np.std(pure_large_zoomed[170:185, 167:182])\n",
    "bkg_std_zone1 = np.nanmean([first_square_std, second_square_std, third_square_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335da59-278a-4d55-ae56-31a9b7d11a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the levels of the contours:\n",
    "levels_164_zone1 = [3*bkg_std_zone1, 5*bkg_std_zone1, 10*bkg_std_zone1, 25*bkg_std_zone1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d67d4-dcb2-4e24-ba01-7ea7e2c8f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "ax = plt.subplot(projection=wHST)   # This is what makes the axis to be recongnized as celestial coordinates\n",
    "plt.imshow(pure_large, cmap = 'gist_gray', vmin = 0, vmax = 0.2, origin = 'lower')    # Image\n",
    "plt.contour(pure_large, colors='red', levels=levels_164_zone1)                        # Contours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3542a22e-2e30-45fa-9c85-80955cb8d978",
   "metadata": {},
   "source": [
    "# Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0b2a3-6425-45b2-a4e0-d8df2b7b7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 2D gaussian function\n",
    "def gaussian_2d(xy, amp, x0, y0, sigma_x, sigma_y):\n",
    "    x, y = xy\n",
    "    return amp * np.exp(-((x - x0)**2 / (2 * sigma_x**2) + (y - y0)**2 / (2 * sigma_y**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f8d95-3470-4baf-b7e2-6a4b14a3e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example, subknot K2b\n",
    "knot2b = pure_large[755:767, 772:787]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a03fc-605d-4085-ae22-2cf4256b1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, knot2b.shape[1])\n",
    "y = np.arange(0, knot2b.shape[0])\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Adjust the 2D gaussian to the image data\n",
    "initial_guess = (np.max(knot2b), knot2b.shape[1] / 2, knot2b.shape[0] / 2, 10, 10)  # Ajuste inicial\n",
    "popt, pcov = opt.curve_fit(gaussian_2d, (X.ravel(), Y.ravel()), knot2b.ravel(), p0=initial_guess)\n",
    "\n",
    "# Extract the fit parameters\n",
    "amp, x0, y0, sigma_x, sigma_y = popt\n",
    "\n",
    "# Compute the 2D gaussian in the same grid than the knot's surface\n",
    "gaussian_fit = gaussian_2d((X, Y), *popt)\n",
    "\n",
    "# Create figure and axis\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# knot2b\n",
    "ax.plot_surface(X, Y, knot2b, edgecolor='royalblue', lw=0.5, rstride=5, cstride=5, alpha=0.3)\n",
    "\n",
    "# 2D gaussian fit\n",
    "ax.plot_surface(X, Y, gaussian_fit, edgecolor='red', lw=0.5, rstride=5, cstride=5, alpha=0.3)\n",
    "\n",
    "# Limits and axis\n",
    "ax.set(xlim=(-5, 15), ylim=(0, 15), zlim=(-0.2, 0.16),\n",
    "       xlabel='X', ylabel='Y', zlabel='Z')\n",
    "\n",
    "plt.title('knot 2b')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b3aac3-a1fd-4b47-a243-f6fcea2b0bef",
   "metadata": {},
   "source": [
    "# Distance between source and knot\n",
    "We can transform between pixel units and celestial coordinates with \"world_to_pixel\" and \"pixel_to_world\"\n",
    "Here I'm going to get the location of the main source as I already know its coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a303c2-87bd-4cbe-b3f0-1516f21155f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_skycoord_radiopeak = SkyCoord(ra='19:14:25.67', dec='11:9:25.45', unit=(u.hourangle, u.deg))  \n",
    "SC_pixel_radiopeak = wHST.world_to_pixel(SC_skycoord_radiopeak)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc53cc6-9925-4422-b358-5d170d0587e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep2b = k2b_centroid_coord.separation(SC_skycoord_radiopeak)       # Separation between the centroid of the knot sand the source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8c7990-9b3e-4853-b09d-0a1ef32e1278",
   "metadata": {},
   "source": [
    "We use the relation \n",
    "\\begin{equation}\n",
    "X(au)=\\alpha ('') \\times d(pc)\n",
    "\\end{equation}\n",
    "where d is the distance between us and the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b58ade-b13f-4b30-ba80-92f28a1fc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_to_knot2b = sep2b.arcsec* 8.4 * 10**3\n",
    "print(f'The distance between our object and the knot 2a is {distance_to_knot2a} au')\n",
    "print(f'The distance between our object and the knot 2b is {distance_to_knot2b} au')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
